{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Problem Set: Diagnosis\n",
    "## Implicates and Implicants for Constraint Programming (50 points)\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Tree Method](#treemethod)\n",
    "3. [Prime implicate method](#prime-implicate)\n",
    "    1. [Detect conflicts](#conflict)\n",
    "    2. [Test validity](#validity)\n",
    "    3. [Test unsatisfiability](#unsatisfiable)\n",
    "    4. [Full algorithm](#full-algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you load the dependencies below by highlighting the cell below and pressing Shift + Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from propositional_state_logic import *\n",
    "from sat_solver import *\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"introduction\"/>\n",
    "</a>\n",
    "\n",
    "In this problem set, you'll answer a theoretical question about the tree method and will also implement a prime implicate generator. This generator helps decrease the size of a model to make diagnosis more efficient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Tree Method (10 Points) <a id=\"treemethod\"/>\n",
    "</a>\n",
    "\n",
    "In this lecture we discussed Slagle's Tree Method (1970) which determines prime implicants through a depth-first search of an ordered tree in which the root \"holds\" all clauses in the theory to be processed. Describe the runtime of the tree method and provide justification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Answer Here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime implicate method <a id=\"prime-implicate\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please refer to the tutorial entitled \"Mini Problem Set Tutorial\", for additional information and guidance on the Prime Implicate Method. Tutorial can be found in the same folder as this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this HW, we will use the thruster model described in the paper, \"Diagnosis: Implicates and Implicants for Constraint Programming\" and covered in lecture. We've also used tools from the Pset 3: Diagnosis, and included some additional ones to facilitate the implementation. First, we will define the model and constraints. Next, we will create stand alone methods to identify if a node is valid, if it is unsatisfiable, or if it is satisfiable. Based on these methods, we will write the full algorithm to generate prime implicates, based on the minimal conflicts that we find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraints:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$(runthruster = on) \\wedge (pressure = high) \\Rightarrow (thruster = thrust)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$(runthruster = on) \\wedge (pressure = low) \\Rightarrow (thruster = nothrust)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$(runthruster = off) \\Rightarrow (thruster = nothrust)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = Problem()\n",
    "\n",
    "# Define the variables for the mini thruster problem with variables: T1, R1, and P3. Returns a Variable object.\n",
    "# Thrust: T1\n",
    "T1 = p.add_variable('thruster', type='finite_domain', domain=['thrust', 'nothrust'])\n",
    "# Thruster: R1\n",
    "R1 = p.add_variable('runthruster', type='finite_domain', domain=['on', 'off'])\n",
    "# Pressure before the thruster: P3\n",
    "P3 = p.add_variable('pressure', type='finite_domain', domain=['high', 'low'])\n",
    "\n",
    "# Add the theory / problem constraints.\n",
    "# The thruster only outputs thrust when it is on and when the input from P3 is high\n",
    "p.add_constraint('runthruster=on & pressure=high => thruster=thrust')\n",
    "p.add_constraint('runthruster=on & pressure=low => thruster=nothrust')\n",
    "p.add_constraint('runthruster=off => thruster=nothrust')\n",
    "\n",
    "# Prints out constraints nicely in LaTeX, so you can check them.\n",
    "display_constraints(p)\n",
    "\n",
    "# Define SAT for future use\n",
    "sat = SATSolver(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block of code, we create the structure of the tree over which we will iterate. In a true sceneario, we would not be searching over all of the tree (to save time), but for the purpose of this exercise, we iterate over all the tree to present the different statuses that a node can have: valid, unsatifiable, satisfiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thruster_model = {\n",
    "    frozenset([T1.get_assignment('thrust')]) : {\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('low')]) : {},\n",
    "        },\n",
    "    \n",
    "    frozenset([T1.get_assignment('nothrust')]) : {\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('low')]) : {},\n",
    "        },\n",
    "    \n",
    "    frozenset([R1.get_assignment('on')]) : {\n",
    "            frozenset([R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([R1.get_assignment('off')]) : {\n",
    "            frozenset([R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "    \n",
    "    frozenset([P3.get_assignment('high')]) : {},\n",
    "    \n",
    "    frozenset([P3.get_assignment('low')]) : {},\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect conflicts <a id=\"conflict\"/>\n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the pruning rules that we have in our tree is to check for conflicts. Thanks to the helper function `check_consistency` that was provided to us for pset 3, it is easy to program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conflict(sat, candidate):\n",
    "    return not sat.check_consistency(candidate)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check our function using assignments for which we know the result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a conflict: This should return true\n",
    "# The thruster cannot thrust if the run thruster command is \"Off\"\n",
    "is_conflict(sat, frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of an assignment that is not a conflict: This should return false\n",
    "# This is not a conflict because the thruster will thrust if the thruster command is \"On\" and the pressure before the thruster is \"High\"\n",
    "is_conflict(sat, frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('high')]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test validity (10 Points) <a id=\"validity\"/>\n",
    "</a>\n",
    "\n",
    "For the second pruning rule, we need to identify if a candidate is valid. A candidate is valid if it is not a conflict and none of its children will be conflicts. We will use a helper function to get all of the children (keys) of a node, based on the structure of the tree we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def get_all_children(d):\n",
    "    for key, value in d.items():\n",
    "        yield key\n",
    "        if isinstance(value, dict):\n",
    "            yield from get_all_children(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this helper function, we can check a candidate's validity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Write Code for Validity Here\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Test Validity\n",
    "\n",
    "# Internal note: we will delete this when we hand it in to the students\n",
    "\n",
    "def is_valid(candidate, sat, thruster_model_children):\n",
    "\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples show an example of a valid candidate and a candidate that is not valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validity Example 1: Candidate that is Not Valid, Should Return \"False\"\n",
    "# Candidate is not valid because it has children such as \"T1 = No Thrust, R1 = On, and P3 = High, which are conflicts\"\n",
    "candidate = frozenset([T1.get_assignment('nothrust')])\n",
    "thruster_model_subset_1 = {\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('low')]) : {},\n",
    "        }\n",
    "\n",
    "is_valid(candidate, sat, thruster_model_subset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validity Example 2: Candidate that is Valid, Should Return \"True\"\n",
    "# Candidate is valid, because if R1 = off and T1 = No thrust, it does not matter what P3 is. T1 should = No thrust whether P3 is high or low\n",
    "candidate = frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')])\n",
    "thruster_model_subset = thruster_model_subset_1[candidate]\n",
    "\n",
    "is_valid(candidate, sat, thruster_model_subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run a series of test on candidates to check the \"is_valid\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These will be NBgrader tests\n",
    "check_validity(is_valid)\n",
    "test_ok()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Unsatisfiability (10 Points) <a id=\"unsatisfiable\"/>\n",
    "</a>\n",
    "\n",
    "We now test for unsatisfiability. Similar to the test for validity, we need to check if a candidate is a conflict, and if all of its children are also conflicts. If any children are consistent with the given constraints (i.e. are not conflicts), it means the candidate is NOT unsatisfiable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Write Code for Unsatisfiability Here\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Test for Unsatisfiability\n",
    "# NOTE: IF THE CANDIDATE ITSELF CONFLICTS WITH THE THEORY, THE CANDIDATE IS UNSATISFIABLE\n",
    "\n",
    "# Internal note: we will delete this when we hand it in to the students\n",
    "\n",
    "def is_unsatisfiable(candidate, sat, thruster_model_children):\n",
    "\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples show an example of an unsatisfiable candidate and a candidate that is not unsatisfiable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsatisfiability Example 1: Candidate that is Unsatisfiable, Should return \"True\"\n",
    "# Candidate \"T1 = Thrust, R1 = Off\" is unsatisfiable because the candidate is a conflict when P3 is both \"High\" and \"Low\", \n",
    "# because T1 cannot thrust when R1 is off\n",
    "candidate = frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')])\n",
    "thruster_model_subset_3 = {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            }\n",
    "\n",
    "is_unsatisfiable(candidate, sat, thruster_model_subset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsatisfiability Example 2: Candidate that is Not Unsatisfiable, Should return \"False\"\n",
    "# This candidate is not unsatisfiable because some of its children are not conflicts. For example,\"T1 = Thrust, R1 = On, P3 = High\" is not a conflict,\n",
    "# because it is a consistent assignement. This is because T1 should thrust when R1 = On and P3 = High\n",
    "candidate = frozenset([T1.get_assignment('thrust')])\n",
    "thruster_model_subset_4 = {\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('low')]) : {},\n",
    "        }\n",
    "\n",
    "is_unsatisfiable(candidate, sat, thruster_model_subset_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run a series of test on candidates to check the \"is_unsatisfiable\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These will be NBgrader tests\n",
    "check_unsatisfiability(is_unsatisfiable)\n",
    "test_ok()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full algorithm: Minimal Conflict Generator (20 Points) <a id=\"full-algorithm\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you will iterate through each of the candidates received from the candidate generator, and determine if they should be either sent back to the generator, converted to an implicate, or added to the solutions list. Your `is_valid` and `is_unsatisfiable` functions from Questions 1 & 2 will be helpful here.\n",
    "\n",
    "Algorithm reminder: if a candidate is valid, it should be sent back to the generator. If a candidate is unsatisfiable, it should be added to the solutions list. If a candidate is satisfiable, it should be converted to an implicate. In this example, assume that a candidate is satisfiable if it is not valid and is not unsatisfiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_implicate_finder(sat, candidateList):\n",
    "    ## sat represents the theory behind the represented model\n",
    "    ## CandidateList: List of Tuples (candidate, thruster_model_children), \n",
    "        # where the candidate is the item to be tested and \n",
    "        # thruster_model_children is a dictionary holding the children of the given candidate\n",
    "    ## generatorAdditions: add candidate to generatorAdditions list when it should go to the generator\n",
    "    ## convertToImplicate: add candidate to the convertToImplicateList when it needs to be converted to an implicate before being passed to the generator\n",
    "    ## solutions: add candidate to the solutions list when a candidate is a minimal conflict\n",
    "    ### Function should return a tuple in the format (generatorAdditions, convertToImplicate, solutions)\n",
    "    \n",
    "    generatorAdditions = []\n",
    "    convertToImplicate = []\n",
    "    solutions = []\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "     \n",
    "    return (generatorAdditions, convertToImplicate, solutions)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example problem simulates the candidate generator providing the candidate tester with 7 candidates. The target results of the candidate tester for this example are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example problem: 7 Candidates given by the candidate generator to the candidate tester\n",
    "\n",
    "candidate1 = frozenset([T1.get_assignment('thrust')])\n",
    "candidate2 = frozenset([T1.get_assignment('nothrust')])\n",
    "candidate4 = frozenset([R1.get_assignment('off')])\n",
    "candidate1A = frozenset([T1.get_assignment('thrust'), R1.get_assignment('on')])\n",
    "candidate1B = frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')])\n",
    "candidate2A = frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on')])\n",
    "candidate2B = frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')])\n",
    "\n",
    "\n",
    "candidateList = [\n",
    "    (candidate1, thruster_model[candidate1]),\n",
    "    (candidate2, thruster_model[candidate2]),\n",
    "    (candidate4, thruster_model[candidate4]),\n",
    "    (candidate1A,thruster_model[candidate1][candidate1A]),\n",
    "    (candidate1B,thruster_model[candidate1][candidate1B]),\n",
    "    (candidate2A,thruster_model[candidate2][candidate2A]),\n",
    "    (candidate2B,thruster_model[candidate2][candidate2B]),\n",
    "]\n",
    "\n",
    "#Test Prime Implicate Algorithm Output: \n",
    "(generatorAdditions, convertToImplicate, solutions) = prime_implicate_finder(sat, candidateList)\n",
    "print(\"Generator Additions: \", generatorAdditions, \"\\n\")\n",
    "print(\"Convert To Implicate: \", convertToImplicate, \"\\n\")\n",
    "print(\"Solutions: \", solutions, \"\\n\")\n",
    "\n",
    "# Output should be: \n",
    "# Generator Additions:  [frozenset({(runthruster = off)}), frozenset({(thruster = nothrust), (runthruster = off)})] \n",
    "# Convert To Implicate:  [frozenset({(thruster = thrust)}), frozenset({(thruster = nothrust)}), frozenset({(thruster = thrust), (runthruster = on)}), frozenset({(thruster = nothrust), (runthruster = on)})] \n",
    "# Solutions:  [frozenset({(runthruster = off), (thruster = thrust)})] \n",
    "# Because 2 of the candidates are found to be valid, 1 is found to be unsatisfiable, and the remaining 4 candidates are determined to be satisfiable\n",
    "# and are converted to implicates "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run a series of tests on larger examples to check the \"prime_implicate_finder\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB Grader Tests\n",
    "check_prime_implicate_finder(prime_implicate_finder)\n",
    "test_ok()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're finished! Confirm that you've answered all 4 questions, and submit the homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
