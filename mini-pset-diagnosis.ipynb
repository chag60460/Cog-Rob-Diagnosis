{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Problem Set: Diagnosis\n",
    "## Implicats and Implicants for Constraint Programming (100 points)\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Prime implicate method](#prime-implicate)\n",
    "    1. [Detect conflicts](#conflict)\n",
    "    2. [Test validity](#validity)\n",
    "    3. [Test unsatisfiability](#unsatisfiable)\n",
    "    4. [Full algorithm](#full-algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you load the dependencies below by highlighting the cell below and pressing Shift + Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from propositional_state_logic import *\n",
    "from sat_solver import *\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"introduction\"/>\n",
    "</a>\n",
    "\n",
    "In this problem set, you'll implement a prime implicate generator. This generator helps decrease the size of a model to make diagnosis more efficient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime implicate method <a id=\"prime-implicate\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We describe the thruster model based on the \"Diagnosis: Implicates and Implicants for Constraint Programming\", which can be found in the tutorial. We've used tools from the Pset 3: Diagnosis, and included some additional ones to facilitate the implementation. First, we will define the model and constraints. Next, we will create stand alone methods to identify if a node is valid, if it is unsatisfiable, or if it is satisfiable. Based on these methods, we will write the full algorithm to generate prime implicates, based on the minimal conflicts that we find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraints:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$(runthruster = on) \\wedge (pressure = high) \\Rightarrow (thruster = thrust)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$(runthruster = on) \\wedge (pressure = low) \\Rightarrow (thruster = nothrust)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$(runthruster = off) \\Rightarrow (thruster = nothrust)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = Problem()\n",
    "\n",
    "# Define the variables for the mini thruster problem with variables: T1, R1, and P3. Returns a Variable object.\n",
    "# Thrust: T1\n",
    "T1 = p.add_variable('thruster', type='finite_domain', domain=['thrust', 'nothrust'])\n",
    "# Thruster: R1\n",
    "R1 = p.add_variable('runthruster', type='finite_domain', domain=['on', 'off'])\n",
    "# Pressure before the thruster: P3\n",
    "P3 = p.add_variable('pressure', type='finite_domain', domain=['high', 'low'])\n",
    "\n",
    "# Add the theory / problem constraints.\n",
    "# The thruster only outputs thrust when it is on and when the input from P3 is high\n",
    "p.add_constraint('runthruster=on & pressure=high => thruster=thrust')\n",
    "p.add_constraint('runthruster=on & pressure=low => thruster=nothrust')\n",
    "p.add_constraint('runthruster=off => thruster=nothrust')\n",
    "\n",
    "# Prints out constraints nicely in LaTeX, so you can check them.\n",
    "display_constraints(p)\n",
    "\n",
    "# Define SAT for future use\n",
    "sat = SATSolver(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block of code, we create the structure of the tree over which we will iterate. In a true sceneario, we would not be searching over all of the tree (to save time), but for the purpose of this exercise, we iterate over all the tree to present the different statuses that a node can have: valid, unsatifiable, satisfiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "thruster_model = {\n",
    "    frozenset([T1.get_assignment('thrust')]) : {\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('low')]) : {},\n",
    "        },\n",
    "    \n",
    "    frozenset([T1.get_assignment('nothrust')]) : {\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('low')]) : {},\n",
    "        },\n",
    "    \n",
    "    frozenset([R1.get_assignment('on')]) : {\n",
    "            frozenset([R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([R1.get_assignment('off')]) : {\n",
    "            frozenset([R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "    \n",
    "    frozenset([P3.get_assignment('high')]) : {},\n",
    "    \n",
    "    frozenset([P3.get_assignment('low')]) : {},\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect conflicts <a id=\"conflict\"/>\n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the pruning rules that we have in our tree is to check for conflicts. Thanks to the helper function $check_consistency$ that was provided to us for pset 3, it is easy to program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conflict(sat, candidate):\n",
    "    return not sat.check_consistency(candidate)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check our function using assignments for which we know the result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be true\n",
    "is_conflict(sat, frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be false\n",
    "is_conflict(sat, frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('high')]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test validity <a id=\"validity\"/>\n",
    "</a>\n",
    "\n",
    "For the second pruning rule, we need to identify if a candidate is valid. In order to do so, we need to check if it is not a conflict, and if all of it children also aren't conflicts. To do so, we will use a helper function to get all of the children (keys) of a node, based on the structure of the tree we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def get_all_keys(d):\n",
    "    for key, value in d.items():\n",
    "        yield key\n",
    "        if isinstance(value, dict):\n",
    "            yield from get_all_keys(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this gelper function, we can check for validity for a candidate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Test Validity\n",
    "def is_valid(candidate, sat, thruster_model_children):\n",
    "    # list of all the following partial assignments\n",
    "    childCandidateList = list(get_all_keys(thruster_model_children))\n",
    "    \n",
    "    for child in childCandidateList:\n",
    "        if is_conflict(sat, child):\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a series of test on candidates that we know are valid or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validity Test 1: Candidate that is Not Valid\n",
    "candidate = frozenset([T1.get_assignment('nothrust')])\n",
    "thruster_model_subset_1 = {\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('nothrust'), P3.get_assignment('low')]) : {},\n",
    "        }\n",
    "\n",
    "is_valid(candidate, sat, thruster_model_subset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validity Test 2: Candidate that is Valid\n",
    "candidate = frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')])\n",
    "thruster_model_subset = thruster_model_subset_1[candidate]\n",
    "\n",
    "is_valid(candidate, sat, thruster_model_subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Unsatisfiability <a id=\"unsatisfiable\"/>\n",
    "</a>\n",
    "\n",
    "We now test for unsatisfiability. Similar to the test for validity, we need to check if a candidate is a conflict, and if all of it children are also conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Test for Unsatisfiability\n",
    "# NOTE: IF THE CANDIDATE ITSELF CONFLICTS WITH THE THEORY, THE CANDIDATE IS UNSATISFIABLE\n",
    "def is_unsatisfiable(candidate, sat, thruster_model_children):\n",
    "    # list of all the following partial assignments\n",
    "    childCandidateList = list(get_all_keys(thruster_model_children))\n",
    "    \n",
    "    if is_conflict(sat, candidate):\n",
    "        return True\n",
    "    \n",
    "    for child in childCandidateList:\n",
    "        if not is_conflict(sat, child): # if one of the children is consistent\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also run a series of test on candidates that we know are unsatisfiable or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsatisfiability Test 1: Candidate that is Unsatisfiable\n",
    "candidate = frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')])\n",
    "thruster_model_subset_3 = {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            }\n",
    "\n",
    "is_unsatisfiable(candidate, sat, thruster_model_subset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsatisfiability Test 2: Candidate that is Not Unsatisfiable\n",
    "candidate = frozenset([T1.get_assignment('thrust')])\n",
    "thruster_model_subset_4 = {\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('on')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('on'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')]) : {\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('high')]) : {},\n",
    "            frozenset([T1.get_assignment('thrust'), R1.get_assignment('off'), P3.get_assignment('low')]) : {},\n",
    "            },\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('high')]) : {},\n",
    "        frozenset([T1.get_assignment('thrust'), P3.get_assignment('low')]) : {},\n",
    "        }\n",
    "\n",
    "is_unsatisfiable(candidate, sat, thruster_model_subset_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full algorithm: Minimal conflict generator <a id=\"full-algorithm\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_implicate_finder(sat, candidateList):\n",
    "    ## sat represents the theory behind the represented model\n",
    "    ## CandidateList: List of Tuples (candidate, thruster_model_children), \n",
    "        # where the candidate is the item to be tested and \n",
    "        # where thruster_model_children is a dictionary holding the children of the given candidate\n",
    "    ## generatorAdditions: add candidate to generatorAdditions list when it should go to the generator\n",
    "    ## convertToImplicate: add candidate to the convertToImplicateList when it needs to be converted to an implicate before being passed to the generator\n",
    "    ## solutions: add candidate to the solutions list when a candidate is a minimal conflict\n",
    "    ### Function should return a tuple in the format (generatorAdditions, convertToImplicate, solutions)\n",
    "    \n",
    "    generatorAdditions = []\n",
    "    convertToImplicate = []\n",
    "    solutions = []\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    for candidateTuple in candidateList: \n",
    "        candidate = candidateTuple[0]\n",
    "        thruster_model_children = candidateTuple[1]\n",
    "        \n",
    "        if is_valid(candidate, sat, thruster_model_children):\n",
    "            generatorAdditions.append(candidate)\n",
    "        elif is_unsatisfiable(candidate, sat, thruster_model_children):\n",
    "            solutions.append(candidate)\n",
    "        else: #candidate is satisfiable\n",
    "            convertToImplicate.append(candidate)\n",
    "            \n",
    "    return (generatorAdditions, convertToImplicate, solutions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Problem\n",
    "\n",
    "candidate1 = frozenset([T1.get_assignment('thrust')])\n",
    "candidate2 = frozenset([T1.get_assignment('nothrust')])\n",
    "candidate4 = frozenset([R1.get_assignment('off')])\n",
    "candidate1A = frozenset([T1.get_assignment('thrust'), R1.get_assignment('on')])\n",
    "candidate1B = frozenset([T1.get_assignment('thrust'), R1.get_assignment('off')])\n",
    "candidate2A = frozenset([T1.get_assignment('nothrust'), R1.get_assignment('on')])\n",
    "candidate2B = frozenset([T1.get_assignment('nothrust'), R1.get_assignment('off')])\n",
    "\n",
    "candidateList = [\n",
    "(candidate1, thruster_model[candidate1]),\n",
    "(candidate2, thruster_model[candidate2]),\n",
    "(candidate4, thruster_model[candidate4]),\n",
    "(candidate1A,thruster_model[candidate1][candidate1A]),\n",
    "(candidate1B,thruster_model[candidate1][candidate1B]),\n",
    "(candidate2A,thruster_model[candidate2][candidate2A]),\n",
    "(candidate2B,thruster_model[candidate2][candidate2B]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Additions:  [frozenset({(runthruster = off)}), frozenset({(runthruster = off), (thruster = nothrust)})] \n",
      "\n",
      "Convert To Implicate:  [frozenset({(thruster = thrust)}), frozenset({(thruster = nothrust)}), frozenset({(runthruster = on), (thruster = thrust)}), frozenset({(thruster = nothrust), (runthruster = on)})] \n",
      "\n",
      "Solutions:  [frozenset({(runthruster = off), (thruster = thrust)})] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Prime Implicate Algorithm Output: \n",
    "\n",
    "(generatorAdditions, convertToImplicate, solutions) = prime_implicate_finder(sat, candidateList)\n",
    "print(\"Generator Additions: \", generatorAdditions, \"\\n\")\n",
    "print(\"Convert To Implicate: \", convertToImplicate, \"\\n\")\n",
    "print(\"Solutions: \", solutions, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
